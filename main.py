import os
import pickle
import numpy as np
import pandas as pd
import hashlib
import sqlite3
import csv
import datetime
import json

import _email, bucket
from mapping import TranslationMap
from utils.utils import generate_datetime, generate_expenses

# GDPR notice: this program can potentially generate real personal data
# Make sure anonymize is TRUE or manually check all generated rows before making anything public

anonymize = False

# Adjust ammount of people / entries to generate
rows = 1000

# Export settings
export_csv = True
export_excel = False
export_sql = False

export_path = 'Exports'
file_name ='tpme_export'

def quick_mail(n, export_as='csv', export_path=export_path, verbose=True):
    """
    Quickly generate n email addresses and export them using the export_manager.

    Parameters:
    - n (int): Number of email addresses to generate.
    - export_as (str, optional): Format in which to export the email addresses (default is 'csv').
    - export_path (str, optional): File path for exporting the generated email addresses (default is export_path).
    - verbose (bool, optional): If True, print progress messages; if False, suppress messages (default is True).

    """

    samples = [_email.gen_email() for i in range(n)]

    if export_path:
        export_manager(samples, export_as, export_path, verbose)

    return samples

def quick_name(n):
    """
    Quickly generates and returns names.
    """

    samples = [gen_name() for i in range(n)]

    return samples


def quick_expenses(n_people=12,
                   n_expenses=200,
                   keyword=None,
                   category=None,
                   timeframe=None):
    """
    Quickly generate synthetic expenses table.
    """

    people = quick_name(n_people)

    expenses_list = []

    for _ in range(n_expenses):
        expense = generate_expenses(keyword, category)

        expense['Person'] = np.random.choice(people)
        expenses_list.append(expense)

    expenses_df = pd.DataFrame(expenses_list)

    return expenses_df




def export_manager(data, export_as='csv', export_path=export_path, verbose=True):

    # Default dir for exporting
    os.makedirs(export_path, exist_ok=True)

    export_as = export_as.lower()

    file_name = f"TPME_{datetime.datetime.now()}"
    header = "Generated by TPME - https://github.com/wlinds/tpme"

    if isinstance(data, list):

        if export_as == 'csv':
            csv_file_path = os.path.join(export_path, f"{file_name}.csv")
            with open(csv_file_path, "w", newline="") as csv_file:
                csv_writer = csv.writer(csv_file)
                csv_writer.writerow([{header}])
                for sample in data:
                    csv_writer.writerow([sample])

        elif export_as == 'json':
            json_file_path = os.path.join(export_path, f"{file_name}.json")
            with open(json_file_path, "w") as json_file:
                json.dump({"emails": data}, json_file, indent=2)

    elif isinstance(data, pd.DataFrame):

        df = value_mapper(data)
    
        if export_as == 'excel' or export_as == 'xlsx':
            pd.DataFrame.to_excel(df, f'{export_path}/{file_name}.xlsx')

        elif export_as == 'sql':
            db_path = f'{export_path}/{file_name}.db'
            con = sqlite3.connect(db_path)
            df.to_sql('People', con=con, if_exists='replace')

    if verbose:
        print(f'Saved as {export_as}: {export_path}/{file_name}')

#------------------------------------ TODO: ------------------------------------------ #

# I slutändan blir det här en tuple med ints som mappas till olika beskrivande namn (utbildning, boende, etc.)
# När fine-tuning av fördelningar kan anses vara färdig går det att formulera mycket enklare och kortare funktion
# för att med sannolikhetsfördelning generera ett nästintill identiskt resultat. 

# Namn (och email) ska 'tokenifieras', annars är all annan data nominaldata (i vissa fall ordinal) med små integers

# ------------------------------------------------------------------------------------ #

# Eftersom nb slumpas innan kvinna/man kan det totala värdet på inparametrar överstiga 1,
# Detta gäller inte för andra funktioner, där sum av alla fördelningar måste vara 1 från början
def gen_gender(female=0.5, male=0.5, nb=0.02):
    if anonymize:
        return 3
    if np.random.uniform() < 1 - nb:
        return np.random.choice([1, 2], p=[1-female, 1-male])
    else:
        return 3

def gen_age(mean=42, std=20, lower_lim=15, upper_lim=100):
  "Normal distribution, default mean of 42 and standard deviation of 20"
  age = int(np.random.normal(loc=mean, scale=std))
  while age <= lower_lim or age >= upper_lim:
      age = int(np.random.normal(loc=mean, scale=std))
  return age

#TODO: Check correlation with age for civilstånd, utbildningsnivå etc.

def gen_civilstånd(age):
  if age <= 25: np.random.choice([1, 5, 6], p=[0.01, 0.98, 0.01])
  if age >= 50: np.random.choice([1, 2, 3, 4, 5, 6,], p=[0.5, 0.05, 0.15, 0.15, 0.10, 0.05])
  return np.random.choice([1, 2, 3, 4, 5, 6], p=[0.35, 0.02, 0.09, 0.04, 0.47, 0.03])
  # TODO: age should clearly be a used more thoughtful

def gen_utbildningsnivå(age):
  if age <= 17: return 1 # Grundskolenivå garanterad för age <= 16
  elif age in range(18,19): return np.random.randint(1, high=3) # Slumpar studentexamen för 18-19 år
  elif age >= 19: return np.random.choice([1, 2, 3, 4, 5, 6], p=[0.01, 0.01, 0.26, 0.21, 0.270, 0.24])
  # allt annat random TODO: implement probability for each age

def gen_sysselsättning(age):
  if age >= 66: return 5 # Garanterar pension över 66
  elif age >= 60: return np.random.choice([1, 4, 5, 6]) # Möjlig pension över 60, ej möjliga studier
  elif age <= 17: return 2 # Garanterar studier under 17
  elif age >= 18 or age <= 30: return np.random.choice([1, 2, 3, 4], p=[0.25, 0.65, 0.05, 0.05]) #Högre sannolikhet att vara student
  return np.random.choice([1, 2, 3, 4, 5, 6], p=[0.7, 0.1, 0.088, 0.086, 0.0, 0.02]) # Speglar arbetslöshet och sjukskrivning i sverige 2022

def gen_boende():
  return np.random.choice([1, 2, 3, 4, 5], p=[0.25, 0.25, 0.49, 0.005, 0.005])
  # VERY ROUGH estimate, probably not even remotely close to actual distribution
  # TODO: add parameters for probability from age and other stuff

def gen_bor_med(age, civilstånd):
  if age <= 17: return 4 # Garanterar boende med förälder under 17
  if age >= 31 or age <= 50: return np.random.choice([1, 2, 3, 4, 5, 6], p=[0.2, 0.1, 0.2, 0.002, 0.002, 0.496]) # ökad sannolikhet att bo med familj i åldersspann 31-50
  if civilstånd == 2 or 3: return np.random.choice([1, 3, 5], p=[0.98, 0.01, 0.01])
  return np.random.choice([1, 2, 3, 5, 6], p=[0.362, 0.4, 0.02, 0.1, 0.118]) # ensamboende speglar scb 2019, resten lekmannaestimering

## ------- Health  ------- ##

def gen_vardagstillfredsställelse():
  "Normal distribution with mean 3 and std 1.6"
  val = int(np.random.normal(loc=3, scale=1.6))
  while val < 1 or val > 5: # prevent values out of range
    val = int(np.random.normal(loc=3, scale=1.6))
  return val
  #TODO: find probability from other parameters such as living situation and age

def gen_health(mean=3, std=1, skewness=0):
    values = np.arange(1, 6)
    z_scores = (values - mean) / std
    probabilities = np.exp(-0.5 * z_scores**2) * (1 + skewness * z_scores)
    probabilities /= np.sum(probabilities)
    return np.random.choice(values, p=probabilities)
  
#TODO:
## ------ Daily/weekly time ------ #

# Arbete	Skötsel	Lek	Rekreation	Sömn
# Time should add up 1440 (24 hours)

# Tid_ensam	Tid_familj	Tid_vänner	Tid_övriga
# time does not have to add up to anything specific but sum cannot be > 1440 (24 hours)

## ------- Name & Contact ------ ##

def gen_name(gender=None):

  # awful structure, TODO: optimize. actually no, the entire name generation shoud be rewritten
  if gender == 1:
    first_bucket = [bucket.f_norwa_list, bucket.f_scandi_gpt, bucket.f_slavic_gpt, bucket.f_sweden_gpt]
  elif gender == 2:  
    first_bucket = [bucket.m_scandi_gpt, bucket.m_slavic_gpt, bucket.m_sweden_gpt]
  elif gender == 3 or gender == None:
    first_bucket = [bucket.f_norwa_list, bucket.f_scandi_gpt, bucket.f_slavic_gpt, bucket.f_sweden_gpt, bucket.m_scandi_gpt, bucket.m_slavic_gpt, bucket.m_sweden_gpt]

  # Just a test set-up. This wouldn't be an issue, but it doesn't take cultural matching first and last names into calculations and is currently limited to some regional variations
  first_name = first_bucket[np.random.randint(0,len(first_bucket))]
  first_name = first_name[np.random.randint(0,len(first_name))]
  
  # Here maybe last names should be adjusted to match first names according to cultural status quo
  last_bucket = [bucket.last_gpt_asia, bucket.last_gpt_eur0, bucket.last_gpt_eur1, bucket.last_gpt_eur2, bucket.last_gpt_mena, bucket.last_swe]
  last_name = last_bucket[np.random.randint(0,len(last_bucket))]
  last_name = last_name[np.random.randint(0,len(last_name))]

  try:
      file_path = 'Data/name_corpus.pkl'
      with open(file_path, 'rb') as f:
          name_corpus = pickle.load(f)

      

  except FileNotFoundError:
      return "nullis corpus"


  return first_name + ' ' + last_name

def new_name(gender): 
  # Experimental function (make changes to this one)
  x = first_bucket[np.random.randint(0,len(first_bucket))]

  return x + ' ' + y

def gen_phone():
  # challenge# 1: needs to be unique
  # for now it will have a probability of 2.474631929433396e-07 to be duplicare

  # Swedish phone# TODO add other 
  a = str(np.random.choice([70, 72, 73, 76, 79]))
  b = np.random.randint(100, high=999)
  c = np.random.randint(100, high=999)

  if anonymize:
    a = 'XX'

  def add_zero(n):
      if n < 10: n = '00' + str(n)
      elif n < 100: n = '0' + str(n)
      return str(n)

  phone = str(0) + a + str(np.random.randint(0,9)) + add_zero(b) + add_zero(c)
  return phone

# Hashing for anonymization
def hash_string(string, end:int):
    sha256_hash = hashlib.sha256(string.encode())
    return sha256_hash.hexdigest()[::end]

class PersonGenerator:
    def __init__(self, anonymize=True):
        self.anonymize = anonymize
        
    def generate_person(self, 
    
        dist_gender = {'female': 0.5, 'male': 0.5, 'nb': 0.02},
        dist_age = {'mean': 42, 'std': 20, 'lower_lim': 15, 'upper_lim': 100},
        dist_health = {'mean': 3, 'std': 1, 'skewness': 0}

        ):

        # Just ints
        age = gen_age(**dist_age)
        phone = gen_phone()
        gendr = gen_gender(**dist_gender)
        civil = gen_civilstånd(age)
        utbil = gen_utbildningsnivå(age)
        syssl = gen_sysselsättning(age)
        boend = gen_boende()
        bormd = gen_bor_med(age, civil)
        vardt = gen_vardagstillfredsställelse()
        hälsa = gen_health(**dist_health)

        # TODO: Token this
        name = gen_name(gendr) # Tokenization has begun! 

        mail = _email.gen_email(name, age, self.anonymize)
        _psw = _email.gen_psw(name, age, self.anonymize)

        # TODO fix this clusterfuck also rename to english
        return (age,name,mail,_psw,phone,gendr,civil,utbil,syssl,boend,bormd,vardt,hälsa)


def value_mapper(person_list, language='english', anonymize=False):
    tm = TranslationMap(language=language)

    df = pd.DataFrame(person_list, columns=[tm.column_names])

    df['Gender'] = df.apply(lambda row: tm.get_translation('Gender', row['Gender']), axis=1)
    df['Marital Status'] = df.apply(lambda row: tm.get_translation('Marital Status', row['Marital Status']), axis=1)
    df['Education'] = df.apply(lambda row: tm.get_translation('Education', row['Education']), axis=1)
    df['Occupation'] = df.apply(lambda row: tm.get_translation('Occupation', row['Occupation']), axis=1)
    df['Accommodation'] = df.apply(lambda row: tm.get_translation('Accommodation', row['Accommodation']), axis=1)
    df['Living with'] = df.apply(lambda row: tm.get_translation('Living with', row['Living with']), axis=1)

    if anonymize:
        print('Hashing selected columns')
        df['Name'] = df['Name'].apply(hash_string, end=8)

    if language == 'swedish':
        df.columns = [tm.column_names_swe]

    return df


if __name__ == '__main__':
    # Create instance of person class
    # pg = PersonGenerator(anonymize=anonymize)
    # person_list = [pg.generate_person() for n in range(rows)]

    # df = value_mapper(person_list)
    # print(df)

    # export_manager(df, export_as='csv')
    # export_manager(df, export_as='json')
    # export_manager(df, export_as='excel')
    # export_manager(df, export_as='sql')

    # print(quick_mail(1000, export_as='csv'))
    # print(quick_mail(1000, export_as='json'))
    # print(quick_mail(1000, export_as='excel'))
    # print(quick_mail(1000, export_as='sql'))


    print(generate_expenses())
    print(quick_expenses())